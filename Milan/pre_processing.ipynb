{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0582d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/env python3\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def load_raw_dataset(input_file_s):\n",
    "    df_s = pd.read_csv(input_file_s, sep=\"\\t\", header=None,\n",
    "                       names=[\"date\", \"time\", \"sensor\", \"value\", \"activity\", \"log\"])\n",
    "    return df_s\n",
    "\n",
    "\n",
    "def clean_and_prepare(df_s):\n",
    "    df_s.log = df_s.log.fillna(method='ffill')\n",
    "    df_s['activity'] = df_s['activity'].fillna(df_s['log'])\n",
    "    df_s['activity'] = df_s['activity'].replace(\"end\", \"Other\")\n",
    "    df_s['activity'] = df_s['activity'].fillna(\"Other\")\n",
    "    df_s['activity'] = df_s['activity'].replace(\"begin\", None)\n",
    "    df_s['activity'] = df_s['activity'].fillna(method='ffill')\n",
    "    return df_s\n",
    "\n",
    "\n",
    "def save_activity_dict(df_s):\n",
    "    filename = \"milan_activity_list_step1.pickle\"\n",
    "    activities = df_s.activity.unique()\n",
    "    # activities.sort()\n",
    "    dictActivities = {}\n",
    "    for i_s, activity in enumerate(activities):\n",
    "        dictActivities[activity] = i_s\n",
    "    pickle_out = open(filename, \"wb\")\n",
    "    pickle.dump(dictActivities, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "\n",
    "def generate_sentence(df2):\n",
    "    sentence = \"\"\n",
    "    sensors = df2.sensor.values\n",
    "    values = df2.value.values\n",
    "    for i_s in range(len(sensors)):\n",
    "        val = values[i_s]\n",
    "        if i_s == len(sensors) - 1:\n",
    "            sentence += \"{}{}\".format(sensors[i_s], val)\n",
    "        else:\n",
    "            sentence += \"{}{} \".format(sensors[i_s], val)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def segment_activities(df_s):\n",
    "    activitiesSeq = []\n",
    "    ponentialIndex = df_s.activity.ne(df_s.activity.shift())\n",
    "    ii = np.where(ponentialIndex == True)[0]\n",
    "    for i_s, end in enumerate(ii):\n",
    "        if i_s > 0:\n",
    "            df_stmp = df_s[ii[i_s - 1]:end]\n",
    "            activitiesSeq.append(df_stmp)\n",
    "    return activitiesSeq\n",
    "\n",
    "\n",
    "def sliding_window(sequence, win_size_s, step_s=1):\n",
    "    try:\n",
    "        iter(sequence)\n",
    "    except TypeError:\n",
    "        raise Exception(\"**ERROR** sequence must be iterable.\")\n",
    "    # if not (isinstance(type(win_size_s), type(0)) and (isinstance(type(step_s), type(0)))):\n",
    "    #     raise Exception(\"**ERROR** type(win_size_s) and type(step_s) must be int.\")\n",
    "    # if step_s > win_size_s:\n",
    "    #     raise Exception(\"**ERROR** step_s must not be larger than win_size_s.\")\n",
    "    numOfChunks = int(((len(sequence) - win_size_s) / step_s) + 1)\n",
    "\n",
    "    if win_size_s > len(sequence):\n",
    "        yield sequence[0:len(sequence)]\n",
    "    else:\n",
    "        for i_s in range(0, numOfChunks * step_s, step_s):\n",
    "            yield sequence[i_s:i_s + win_size_s]\n",
    "\n",
    "\n",
    "def sequences_to_sentences(activity_sequences_s):\n",
    "    sentences_s = []\n",
    "    label_sentences_s = []\n",
    "    for i_s in range(len(activity_sequences_s)):\n",
    "        sentence = generate_sentence(activity_sequences_s[i_s])\n",
    "        sentences_s.append(sentence)\n",
    "        label_sentences_s.append(activity_sequences_s[i_s].activity.values[0])\n",
    "    return sentences_s, label_sentences_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16979bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Load dataset\n",
      "STEP 2: prepare dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p7/20f7xrt504ncpy6nhf4tjw480000gn/T/ipykernel_3149/4117254466.py:19: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_s.log = df_s.log.fillna(method='ffill')\n",
      "/var/folders/p7/20f7xrt504ncpy6nhf4tjw480000gn/T/ipykernel_3149/4117254466.py:24: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_s['activity'] = df_s['activity'].fillna(method='ffill')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "save_activity_dict() missing 1 required positional argument: 'input_file_s'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTEP 2: prepare dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m df \u001b[38;5;241m=\u001b[39m clean_and_prepare(df)\n\u001b[0;32m---> 12\u001b[0m \u001b[43msave_activity_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[:\u001b[38;5;241m30\u001b[39m])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#  Segment dataset in sequence of activity ##\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: save_activity_dict() missing 1 required positional argument: 'input_file_s'"
     ]
    }
   ],
   "source": [
    "\n",
    "input_file = r\"/\"\n",
    "win_size = 100\n",
    "step = 1\n",
    "\n",
    "print(\"STEP 1: Load dataset\")\n",
    "df = pd.read_csv(\"data_milan\",\n",
    "                 sep='\\t', header=None, names=[\"date\",\"time\", \"sensor\",\n",
    "                                               \"value\", \"activity\", \"log\"])\n",
    "\n",
    "print(\"STEP 2: prepare dataset\")\n",
    "df = clean_and_prepare(df)\n",
    "save_activity_dict(df)\n",
    "print(df[:30])\n",
    "\n",
    "#  Segment dataset in sequence of activity ##\n",
    "print(\"STEP 3: segment dataset in sequence of activity\")\n",
    "activity_sequences = segment_activities(df)\n",
    "print(activity_sequences[:10])\n",
    "df_txt = df.iloc[:, :-2]\n",
    "#df_txt.to_csv('dataframe.txt', sep='\\t', index=False)\n",
    "\n",
    "\n",
    "#  Transform sequences of activity in sentences ##\n",
    "print(\"STEP 4: transform sequences of activity in sentences\")\n",
    "sentences, label_sentences = sequences_to_sentences(activity_sequences)\n",
    "print(sentences[0:5])\n",
    "##################################################################################################################\n",
    "#print(label_sentences[0:8])\n",
    "#['Sleeping', 'Other', 'Bed_to_Toilet', 'Other', 'Sleeping']\n",
    "np.save(\"origin_label.npy\",label_sentences)\n",
    "\n",
    "#  Indexization ##\n",
    "print(\"STEP 5: sentences indexization\")\n",
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "indexed_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "# for word, index in word_index.items():\n",
    "#     print(f\"{word}: {index}\")\n",
    "##print(word_index)\n",
    "##################################################################################################################\n",
    "print(indexed_sentences[:5])\n",
    "#[[26, 25, 26, 25, 26, 25, 26, 25, 26, 50, 49, 25, 26, 50, 49, 25, 26, 50, 10, 49, 9, 25, 26, 10, 25], [26, 28, 25], \n",
    "#[42, 27, 9, 41, 42, 41, 10, 42, 9, 10, 28, 41], [27, 9, 10, 9],\n",
    "#[26, 25, 50, 26, 49, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 50, 49, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 10, 25, 9, 26, 10, 25, 26, 25]]\n",
    "\n",
    "#  Split in sliding windows ##\n",
    "print(\"STEP 6: split indexed sentences in sliding windows\")\n",
    "X_windowed = []\n",
    "Y_windowed = []\n",
    "X_windowed_sen = []\n",
    "Y_windowed_sen = []\n",
    "for i, s in enumerate(indexed_sentences):\n",
    "    chunks = sliding_window(s, win_size, step)\n",
    "    for chunk in chunks:\n",
    "        X_windowed.append(chunk)\n",
    "        Y_windowed.append(label_sentences[i])\n",
    "print(X_windowed[0:5])\n",
    "print(Y_windowed[0:5])\n",
    "\n",
    "        \n",
    "#  Pad windows ##\n",
    "print(\"STEP 7: pad sliding windows\")\n",
    "padded_windows = pad_sequences(X_windowed, padding ='post')\n",
    "Y_windowed = np.array(Y_windowed)\n",
    "print(padded_windows[0:10])\n",
    "print(Y_windowed[0:10])\n",
    "print(np.unique(Y_windowed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0623f20e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dictActivities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdictActivities\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dictActivities' is not defined"
     ]
    }
   ],
   "source": [
    "print(dictActivities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85896d29-9e59-404c-9fdd-dcd12421c0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 8: save sliding windows and labels\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'milan_activity_list_step1.pickle.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pickle_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pickle_file:\n\u001b[1;32m      7\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(indexed_sentences, pickle_file)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmilan_activity_list_step1.pickle.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mdict\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/csi/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'milan_activity_list_step1.pickle.pkl'"
     ]
    }
   ],
   "source": [
    "# #  Save files ##\n",
    "print(\"STEP 8: save sliding windows and labels\")\n",
    "np.save(\"X.npy\", padded_windows)\n",
    "np.save(\"Y_prepare.npy\", Y_windowed)\n",
    "pickle_file_path = 'milan_activity_list_step1.pickle'\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(indexed_sentences, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e074d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sleeping': 0, 'Other': 1, 'Bed_to_Toilet': 2, 'Meal_Preparation': 3, 'Relax': 4, 'Housekeeping': 5, 'Eating': 6, 'Wash_Dishes': 7, 'Leave_Home': 8, 'Enter_Home': 9, 'Work': 10, 'Respirate': 11}\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/zehaokou/Desktop/Technion/AI/plot/new_processing/aruba_activity_list_step1.pickle', 'rb') as f:\n",
    "    dict = pickle.load(f)\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7680eb60",
   "metadata": {},
   "source": [
    "# Replace Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c47ebe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sleeping' 'Other' 'Bed_to_Toilet' 'Other' 'Sleeping' 'Other'\n",
      " 'Meal_Preparation' 'Meal_Preparation' 'Meal_Preparation'\n",
      " 'Meal_Preparation']\n",
      "[[26 25 26 25 26 25 26 25 26 50 49 25 26 50 49 25 26 50 10 49  9 25 26 10\n",
      "  25  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0]\n",
      " [26 28 25  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0]\n",
      " [42 27  9 41 42 41 10 42  9 10 28 41  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0]\n",
      " [27  9 10  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0]\n",
      " [26 25 50 26 49 25 26 25 26 25 26 25 26 25 26 25 26 25 26 25 26 25 26 25\n",
      "  26 25 26 25 26 25 26 25 26 25 26 50 49 25 26 25 26 25 26 25 26 25 26 25\n",
      "  26 25 26 10 25  9 26 10 25 26 25  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0]]\n",
      "[[26, 25, 26, 25, 26, 25, 26, 25, 26, 50, 49, 25, 26, 50, 49, 25, 26, 50, 10, 49, 9, 25, 26, 10, 25], [26, 28, 25], [42, 27, 9, 41, 42, 41, 10, 42, 9, 10, 28, 41], [27, 9, 10, 9], [26, 25, 50, 26, 49, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 50, 49, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 25, 26, 10, 25, 9, 26, 10, 25, 26, 25], [9, 10, 9, 10, 9, 28, 10, 27, 28, 27, 42, 41, 9, 10, 42, 41, 28, 27, 38, 30, 9, 3, 37, 29, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 22, 21, 4, 3, 62, 61, 4, 3, 4, 3, 4, 3, 33, 13, 34, 4, 14, 3, 4, 11, 12, 13, 3, 14, 4, 1, 3, 2, 1, 4, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 3, 22, 13, 21, 2, 4, 14, 3, 11, 4, 12], [15, 6, 8, 16, 5, 7, 6, 5, 6, 5, 6, 8, 5, 7, 6, 8, 7, 5, 8, 7, 6, 5, 8, 7, 8, 6, 5, 6, 5, 7, 8, 7, 8, 6, 7, 5, 6, 8, 5, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 6, 7, 5, 6, 8, 7, 5, 6, 5, 6, 5, 15, 6, 8, 16, 5, 7, 6, 5, 6, 5, 6, 5, 6, 5, 6, 5, 6, 8, 36, 7, 35, 5, 6, 5, 6, 36, 35, 5, 6, 5, 6, 5, 36, 6, 5, 6, 8, 35, 7, 5, 8, 7, 6, 5, 15, 16, 15, 6, 5, 16, 15, 6, 5, 6, 5, 6, 5, 16, 15, 16, 15, 6, 5, 16, 15, 6, 5, 16, 6, 15, 16, 5, 15, 6, 5, 16, 6, 5, 6, 15, 16, 5, 6, 5, 15, 6, 5, 16, 6, 5, 6, 5, 6, 5, 6, 5, 6, 5, 6, 8, 7, 8, 5, 6, 7, 8, 7, 5, 8, 7, 8, 7, 6, 5, 8, 6, 7, 15, 5, 8, 6, 16, 5, 6, 5, 7, 8, 6, 5, 6, 5, 6, 5, 7, 6, 8, 7, 8, 7, 15, 5, 16, 6, 5, 8, 7, 6, 36, 35, 5, 6, 36, 35, 5, 6, 36, 35, 5, 6, 8, 7, 5, 6, 8, 5, 6, 36, 7, 35, 15, 5, 16, 15, 3, 16, 4, 15, 16, 15, 16, 15, 16, 15, 20, 19, 16, 15, 16, 15, 3, 16], [4, 3, 4, 3, 4, 24, 3, 32, 4, 23, 31, 46, 32, 45, 24, 31, 23, 3, 4, 3, 30, 38, 29, 4, 37, 38, 37, 10, 9, 10, 28, 27, 9, 10, 28, 27, 9, 10, 9, 10, 9, 10, 9, 10, 9, 10, 9, 10, 9, 10, 28, 27, 9, 10, 28, 9, 10, 9, 27, 10, 28, 27, 9, 10, 28, 9, 10, 27, 9, 28, 27, 28, 10, 9, 27, 28, 27, 28, 10, 27, 9, 10, 9, 10, 28, 9, 27, 38, 30, 3, 37, 29, 4, 32, 31, 24, 3, 23, 38, 30, 10, 4, 37, 29, 9, 10, 28, 42, 27, 9, 10, 41, 9, 10, 9, 10, 9, 10, 48, 47, 28, 9, 27, 10, 28, 9, 27, 10, 9, 38, 30, 3, 37, 29, 4, 11, 12, 6], [15, 5, 20, 16, 19, 20, 6, 19, 5, 6, 8, 7, 5, 8, 6, 7, 5, 6, 5, 6, 8, 36, 7, 5, 35, 36, 6, 35, 8, 7, 5, 6, 5, 6, 15, 5, 16, 15, 6, 16, 5, 6, 15, 5, 6, 16], [5, 3, 4, 3, 11, 13, 12, 4, 1, 14, 22, 2, 21, 22, 21, 1, 22, 3, 4, 2, 3, 33, 34, 21, 33, 4, 3, 1, 34, 13, 2, 14, 4, 3, 4, 3, 4, 11, 12, 15, 6, 16, 5, 15, 6, 24, 5, 16, 32, 23, 46, 31, 45, 46, 18, 45, 17, 18, 17, 18, 17, 18, 17, 18, 17, 18, 46, 17, 32, 45, 24, 31, 15, 16, 23, 11, 3, 12, 30, 38, 37, 29, 10, 4, 28, 42, 27, 9, 41, 42, 10, 28, 41, 38, 30, 3, 9, 27, 37, 24, 29, 15, 23, 6, 4, 16, 5, 6, 15, 16, 5, 15, 6, 5, 24, 32, 16, 46, 23, 31, 18, 45, 17, 18, 17, 18, 17, 18, 46, 17, 32, 45, 24, 31, 15, 6, 23, 8, 16, 5, 6, 36, 7, 66, 5, 6, 5, 35, 36, 35, 36, 6, 5, 65, 35, 36, 35, 36, 6, 35, 5, 8, 6, 15, 7, 5, 24, 16, 3, 23, 4, 1, 13, 3, 14, 4, 2]]\n",
      "[0 1 2 1 0 1 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "y = np.load(\"Y_prepare.npy\")\n",
    "y0 = np.load(\"X_prepare.npy\")\n",
    "print(y[0:10])\n",
    "print(y0[0:5])\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "print(loaded_data[:10])\n",
    "\n",
    "# ['Bed_to_Toilet' 'Chores' 'Desk_Activity' 'Dining_Rm_Activity' 'Eve_Meds' 'Guest_Bathroom' 'Kitchen_Activity' 'Leave_Home' 'Master_Bathroom' 'Master_Bedroom_Activity' 'Meditate' 'Morning_Meds' 'Other' 'Read' 'Sleep' 'Watch_TV']\n",
    "dict = {'Sleeping': 0, 'Other': 1, 'Bed_to_Toilet': 2, 'Meal_Preparation': 3, 'Relax': 4, 'Housekeeping': 5, 'Eating': 6, 'Wash_Dishes': 7, 'Leave_Home': 8, 'Enter_Home': 9, 'Work': 10, 'Respirate': 11}\n",
    "y1 = np.array(list(map(dict.get, y)))\n",
    "print(y1[0:10])\n",
    "np.save(\"/Users/zehaokou/Desktop/Paper1/PCA/Aruba/no_D123M31/Y_noD123M31.npy\", y1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa4669a",
   "metadata": {},
   "source": [
    "# Replace X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95cd3c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# a = np.load('/Users/zehaokou/Desktop/Technion/'\n",
    "#             'AI/plot/pre_processed_datasets/ARUBA/'\n",
    "#             'Aruba_250_padded_x_DCNN.npy')\n",
    "#a = np.load('/Users/zehaokou/Desktop/Technion/AI/plot/new_processing/new_processing_100_padded_x_step1.npy')\n",
    "# a = np.load('/Users/zehaokou/Desktop/Technion/AI/plot/new_processing_100_padded_x_step1_state.npy')\n",
    "a = np.load('/Users/zehaokou/Desktop/Paper1/PCA/Aruba/no_D123M31/Aruba_x_noD123M31.npy')\n",
    "a = a.astype(float)\n",
    "\n",
    "# Dinning\n",
    "a[np.where(a == 0)] = np.nan\n",
    "a[np.where(a == 11)] = 1039\n",
    "a[np.where(a == 12)] = 1038.9\n",
    "\n",
    "# Kitchen\n",
    "a[np.where(a == 5)] = 1053.9\n",
    "a[np.where(a == 6)] = 1054\n",
    "a[np.where(a == 7)] = 1049.9\n",
    "a[np.where(a == 8)] = 1050\n",
    "a[np.where(a == 15)] = 1053\n",
    "a[np.where(a == 16)] = 1052.9\n",
    "a[np.where(a == 19)] = 1051.9\n",
    "a[np.where(a == 20)] = 1052\n",
    "a[np.where(a == 35)] = 1050.9\n",
    "a[np.where(a == 36)] = 1051\n",
    "\n",
    "# Living\n",
    "a[np.where(a == 1)] = 1035\n",
    "a[np.where(a == 2)] = 1034.9\n",
    "a[np.where(a == 3)] = 1040\n",
    "a[np.where(a == 4)] = 1039.9\n",
    "a[np.where(a == 13)] = 1038\n",
    "a[np.where(a == 14)] = 1037.9\n",
    "a[np.where(a == 21)] = 1035.9\n",
    "a[np.where(a == 22)] = 1036\n",
    "a[np.where(a == 33)] = 1037\n",
    "a[np.where(a == 34)] = 1036.9\n",
    "\n",
    "# Office\n",
    "a[np.where(a == 39)] = 1080.9\n",
    "a[np.where(a == 40)] = 1081\n",
    "a[np.where(a == 43)] = 1081.9\n",
    "a[np.where(a == 44)] = 1082\n",
    "a[np.where(a == 53)] = 1082.9\n",
    "a[np.where(a == 54)] = 1083\n",
    "a[np.where(a == 59)] = 1079.9\n",
    "a[np.where(a == 60)] = 1080\n",
    "\n",
    "# Bed 1\n",
    "a[np.where(a == 9)] = 1025.9\n",
    "a[np.where(a == 10)] = 1026\n",
    "a[np.where(a == 25)] = 1021.9\n",
    "a[np.where(a == 26)] = 1022\n",
    "a[np.where(a == 27)] = 1023.9\n",
    "a[np.where(a == 28)] = 1024\n",
    "a[np.where(a == 37)] = 1024.9\n",
    "a[np.where(a == 38)] = 1025\n",
    "a[np.where(a == 41)] = 1022.9\n",
    "a[np.where(a == 42)] = 1023\n",
    "a[np.where(a == 47)] = 1019.9\n",
    "a[np.where(a == 48)] = 1020\n",
    "a[np.where(a == 49)] = 1020.9\n",
    "a[np.where(a == 50)] = 1021\n",
    "\n",
    "# Bed 2\n",
    "a[np.where(a == 17)] = 1071.9\n",
    "a[np.where(a == 18)] = 1072\n",
    "a[np.where(a == 45)] = 1070.9\n",
    "a[np.where(a == 46)] = 1071\n",
    "\n",
    "# Bathroom\n",
    "a[np.where(a == 51)] = 1099.9\n",
    "a[np.where(a == 52)] = 1091\n",
    "a[np.where(a == 55)] = 1090\n",
    "a[np.where(a == 56)] = 1089.9\n",
    "# a[np.where(a == 94)] = 1100\n",
    "# a[np.where(a == 95)] = 1100\n",
    "\n",
    "# Door\n",
    "a[np.where(a == 57)] = 1139.9\n",
    "a[np.where(a == 58)] = 1140\n",
    "a[np.where(a == 67)] = 1119.9\n",
    "a[np.where(a == 68)] = 1120\n",
    "# a[np.where(a == 169)] = 1110\n",
    "# a[np.where(a == 170)] = 1110\n",
    "# a[np.where(a == 177)] = 1120\n",
    "# a[np.where(a == 178)] = 1120\n",
    "a[np.where(a == 65)] = 1109.9\n",
    "a[np.where(a == 66)] = 1110\n",
    "\n",
    "# Corridor\n",
    "a[np.where(a == 23)] = 1059.9\n",
    "a[np.where(a == 24)] = 1060\n",
    "a[np.where(a == 29)] = 1026.9\n",
    "a[np.where(a == 30)] = 1027\n",
    "a[np.where(a == 31)] = 1060.9\n",
    "a[np.where(a == 32)] = 1061\n",
    "a[np.where(a == 61)] = 1033.9\n",
    "a[np.where(a == 62)] = 1034\n",
    "\n",
    "# Temperature\n",
    "\n",
    "a[np.where(a == 63)] = np.nan\n",
    "a[np.where(a == 64)] = np.nan\n",
    "a[np.where(a == 65)] = np.nan\n",
    "a[np.where(a == 66)] = np.nan\n",
    "for i in np.linspace(69, 93, 93-69+1):\n",
    "    a[np.where(a == i)] = np.nan\n",
    "a[np.where(a == 96)] = np.nan\n",
    "a[np.where(a == 171)] = np.nan\n",
    "a[np.where(a == 172)] = np.nan\n",
    "a[np.where(a == 173)] = np.nan\n",
    "a[np.where(a == 174)] = np.nan\n",
    "a[np.where(a == 175)] = np.nan\n",
    "a[np.where(a == 176)] = np.nan\n",
    "for i in np.linspace(96, 169, 169-96+1):\n",
    "    a[np.where(a == i)] = np.nan\n",
    "for i in np.linspace(179, 300, 300-179+1):\n",
    "    a[np.where(a == i)] = np.nan\n",
    "\n",
    "\n",
    "after_change_index = a-1000\n",
    "np.save(\"//Users/zehaokou/Desktop/Paper1/PCA/Aruba/no_D123M31/state_index.npy\", after_change_index)\n",
    "print('ok')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
